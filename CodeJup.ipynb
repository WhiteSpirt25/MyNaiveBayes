{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import log\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создал кастомный класс "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class naive_bais:\n",
    "    clasFreq = dict()\n",
    "    wordProbs = {}\n",
    "    classes = []\n",
    "    \n",
    "    # Counts words in each class and returns dictionary [class:Counter for words in class]\n",
    "    def count(self,X,Y):\n",
    "        wordDict = dict()\n",
    "        for clas in self.classes:\n",
    "            wordCounter = Counter()\n",
    "            for i in range(len(X)):\n",
    "                if Y[i] == clas:\n",
    "                    text = X[i].lower().split()\n",
    "                    wordCounter.update(text)\n",
    "            wordDict.update({clas:dict(wordCounter)})\n",
    "        return wordDict\n",
    "\n",
    "    def fit(self,X, Y):\n",
    "        # classes\n",
    "        classes = Counter()\n",
    "        classes.update(Y)\n",
    "        \n",
    "        self.classes = list(classes)\n",
    "        clasFreq = classes.most_common()\n",
    "        for i in range(len(clasFreq)):\n",
    "            clasFreq[i] = (clasFreq[i][0], float(clasFreq[i][1]) / len(Y))\n",
    "        clasFreq = dict(clasFreq)\n",
    "\n",
    "        \n",
    "        words = self.count(X,Y)\n",
    "\n",
    "        # word frequency in classes\n",
    "        wordProbs = {}\n",
    "        self.unique_words = len(words.get(\"ham\",[])) + len(words.get(\"spam\",[]))\n",
    "        for clas in self.classes:\n",
    "            \n",
    "            totalWords = sum(words[clas].values())\n",
    "            wordProb = {}\n",
    "            denom = self.unique_words + totalWords\n",
    "            \n",
    "            for word in words[clas]:\n",
    "                wordProb.update([(word,log( ( words[clas][word]+1 )/ denom ))])\n",
    "                \n",
    "            wordProb.update([(\"-\",-log( denom ))])\n",
    "            wordProbs.update({clas: wordProb})\n",
    "            \n",
    "        self.clasFreq = clasFreq\n",
    "        self.wordProbs = wordProbs\n",
    "\n",
    "    def predict1(self, text):\n",
    "        # splitting\n",
    "        temp = text.split()\n",
    "        bestClass = self.classes[0]\n",
    "        bestScore = -999999999.\n",
    "        \n",
    "        for clas in self.classes:\n",
    "            score = log(self.clasFreq[clas])\n",
    "            \n",
    "            for word in temp:\n",
    "                if word in self.wordProbs[clas]:\n",
    "                    prob = self.wordProbs[clas][word]\n",
    "                else:\n",
    "                    prob = self.wordProbs[clas][\"-\"]\n",
    "                score += prob\n",
    "                \n",
    "            if score > bestScore:\n",
    "                bestClass = clas\n",
    "                bestScore = score\n",
    "                \n",
    "        return bestClass\n",
    "\n",
    "    def predict(self,arr):\n",
    "        ans = []\n",
    "        for text in arr:\n",
    "            ans.append(self.predict1(text))\n",
    "        return ans\n",
    "    def get_params(self, deep=True): # Сделано только что бы cross_val_score работал\n",
    "        return dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В этот добавлен TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class naive_bais_tf:\n",
    "    clasFreq = dict()\n",
    "    wordProbs = {}\n",
    "    classes = []\n",
    "    \n",
    "    # Counts words in each class and returns dictionary [class:Counter for words in class]\n",
    "    def count(self,X,Y):\n",
    "        wordDict = dict()\n",
    "        for clas in self.classes:\n",
    "            wordCounter = Counter()\n",
    "            for i in range(len(X)):\n",
    "                if Y[i] == clas:\n",
    "                    text = X[i].lower().split()\n",
    "                    wordCounter.update(text)\n",
    "            wordDict.update({clas:dict(wordCounter)})\n",
    "        return wordDict\n",
    "    def count_idf(self,X):\n",
    "        doc_words = []\n",
    "        unique_words = set()\n",
    "        for doc in X:\n",
    "            doc_words.append(doc.lower().split())\n",
    "            for word in doc_words[-1]:\n",
    "                unique_words.add(word)\n",
    "        idf = dict()\n",
    "        for word in unique_words:\n",
    "            num_of_doc = 0\n",
    "            for doc in doc_words:\n",
    "                if word in doc:\n",
    "                    num_of_doc +=1\n",
    "            idf.update({word:log( (1+len(X)) / (1 + num_of_doc) )})\n",
    "        return idf\n",
    "    def sum_idf(self,idf_dict,class_words):\n",
    "        res = 0\n",
    "        for word in class_words:\n",
    "            res += class_words[word] * idf_dict[word]\n",
    "        return res\n",
    "    def fit(self,X, Y):\n",
    "        # classes\n",
    "        classes = Counter()\n",
    "        classes.update(Y)\n",
    "        \n",
    "        self.classes = list(classes)\n",
    "        clasFreq = classes.most_common()\n",
    "        for i in range(len(clasFreq)):\n",
    "            clasFreq[i] = (clasFreq[i][0], float(clasFreq[i][1]) / len(Y))\n",
    "        clasFreq = dict(clasFreq)\n",
    "\n",
    "        \n",
    "        words = self.count(X,Y)\n",
    "        IDF = self.count_idf(X)\n",
    "\n",
    "        # word frequency in classes\n",
    "        wordProbs = {}\n",
    "        self.unique_words = len(words.get(\"ham\",[])) + len(words.get(\"spam\",[]))\n",
    "        for clas in self.classes:\n",
    "            \n",
    "            totalWords = sum(words[clas].values())\n",
    "            wordProb = {}\n",
    "            denom = self.unique_words + totalWords\n",
    "            \n",
    "            for word in words[clas]:\n",
    "                wordProb.update([(word,log( ( words[clas][word]+1 ) * IDF[word] / denom ))])\n",
    "                \n",
    "            wordProb.update([(\"-\",-log( denom ))])\n",
    "            wordProbs.update({clas: wordProb})\n",
    "            \n",
    "        self.clasFreq = clasFreq\n",
    "        self.wordProbs = wordProbs\n",
    "\n",
    "    def predict1(self, text):\n",
    "        # splitting\n",
    "        temp = text.split()\n",
    "        bestClass = self.classes[0]\n",
    "        bestScore = -999999999.\n",
    "        \n",
    "        for clas in self.classes:\n",
    "            score = log(self.clasFreq[clas])\n",
    "            \n",
    "            for word in temp:\n",
    "                if word in self.wordProbs[clas]:\n",
    "                    prob = self.wordProbs[clas][word]\n",
    "                else:\n",
    "                    prob = self.wordProbs[clas][\"-\"]\n",
    "                score += prob\n",
    "                \n",
    "            if score > bestScore:\n",
    "                bestClass = clas\n",
    "                bestScore = score\n",
    "                \n",
    "        return bestClass\n",
    "\n",
    "    def predict(self,arr):\n",
    "        ans = []\n",
    "        for text in arr:\n",
    "            ans.append(self.predict1(text))\n",
    "        return ans\n",
    "    def get_params(self, deep=True): # Сделано только что бы cross_val_score работал\n",
    "        return dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing\n",
    "file = open(\"SMSSpamCollection\", encoding=\"utf8\")\n",
    "file = file.read()\n",
    "file = file.translate({ord(c): None for c in '1234567890.,-:!?\"\\'/«»„“();'})\n",
    "lines = file.split('\\n')\n",
    "data = []\n",
    "for i in range(len(lines)):\n",
    "    data.append(lines[i].split('\\t'))\n",
    "data.pop()\n",
    "X = []\n",
    "Y = []\n",
    "for row in data:\n",
    "    Y.append(row[0])\n",
    "    X.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = \\\n",
    "    train_test_split(X,Y,test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Протестировал на работоспособность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9211956521739131\n"
     ]
    }
   ],
   "source": [
    "clf = naive_bais()\n",
    "clf.fit(x_train,y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Для сравнения запустил аналог из Sklearn \n",
    "#### Без TF-IDF так она делает только хуже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9728260869565217\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "skclf = naive_bayes.MultinomialNB()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X)\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "x_trainT,x_testT,y_trainT,y_testT = \\\n",
    "    train_test_split(X_train_counts,Y,test_size=0.33)\n",
    "skclf.fit(x_trainT,y_trainT)\n",
    "print(accuracy_score(y_testT,skclf.predict(x_testT)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравним результаты классификаторов на кросс валидации с 5 делениями по точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My NB\n",
      "Accuracy: 0.93 (+/- 0.02)\n",
      "Sklearn NB\n",
      "Accuracy: 0.97 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, X,Y,scoring = 'accuracy',cv=5)\n",
    "print(\"My NB\\nAccuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(skclf,X_train_counts,Y,scoring = 'accuracy',cv=5)\n",
    "print(\"Sklearn NB\\nAccuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Так как выборка несбалансированна (14:86) сравним результаты классификаторов на кросс валидации с 5 делениями по f1 score которая более показательна\n",
    "#### Выбрал F1 а не roc-auc ,так как он более внимателен к ошибкам нежели к попаданиям что в нашем случае важнее так как нельзя помечать ham ,как spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "encoded_column_vector = label_binarize(Y, classes=['ham','spam']) # ham will be 0 and spam will be 1\n",
    "Yb = np.ravel(encoded_column_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My NB\n",
      "F1: 0.57 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X,Yb,scoring = 'f1',cv=5)\n",
    "print(\"My NB\\nF1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn NB\n",
      "F1: 0.90 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(skclf,X_train_counts,Yb,scoring = 'f1',cv=5)\n",
    "print(\"Sklearn NB\\nF1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теперь проверим с TF-TDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = naive_bais_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My NB+TF-IDF\n",
      "Accuracy: 0.94 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X,Y,scoring = 'accuracy',cv=5)\n",
    "print(\"My NB+TF-IDF\\nAccuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My NB+TF-IDF\n",
      "F1: 0.70 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X,Yb,scoring = 'f1',cv=5)\n",
    "print(\"My NB+TF-IDF\\nF1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод:\n",
    "#### До Sklearn-а далеко, но рабочий алгоритм написан собственными руками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
